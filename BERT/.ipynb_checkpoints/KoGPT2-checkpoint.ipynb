{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f96580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel\n",
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c42e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153e134ab100417687f8c0d618eb4d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69555f7f71b2498db092b2db49d80b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/490M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766704d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37d605f913144a5af0074995ef3f1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('skt/kogpt2-base-v2', bos_token='</s>',\n",
    "                                                   eos_token='</s', unk_token='<unk>',\n",
    "                                                   pad_token='<pad>', mask_token='<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89fb1e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25906, 8702, 7801, 25856, 34407, 10528, 422, 426, 18258, 14652, 21154]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"안녕하세요. 한국어 GPT-2 모델입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6295a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoGPT2 모델을 이용해서 문장 생성하기\n",
    "text = '근육이 커지기 위해서는'\n",
    "input_ids = tokenizer.encode(text)\n",
    "gen_ids = model.generate(torch.tensor([input_ids]),\n",
    "                        max_length = 128,\n",
    "                        repetition_penalty=2.0,\n",
    "                        pad_token_id = tokenizer.pad_token_id,\n",
    "                        eos_token_id = tokenizer.eos_token_id,\n",
    "                        unk_token_id = tokenizer.unk_token_id,\n",
    "                        bos_token_id = tokenizer.bos_token_id,\n",
    "                        use_cache=True)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "generated = tokenizer.decode(gen_ids[0,:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc2b299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33245, 10114, 12748, 11357, 23879, 39306,  9684,  7884, 10211, 15177,\n",
       "         26421,   387, 17339,  7889,  9908, 15768,  6903, 15386,  8146, 12923,\n",
       "          9228, 18651, 42600,  9564, 17764,  9033,  9199, 14441,  7335,  8704,\n",
       "         12557, 32030,  9510, 18595,  9025, 10571, 25741, 10599, 13229,  9508,\n",
       "          7965,  8425, 33102,  9122, 21240,  9801, 32106, 13579, 12442, 13235,\n",
       "         19430,  8022, 12972,  9566, 11178,  9554, 24873,  7198,  9391, 12486,\n",
       "          8711,  9346,  7071, 36736,  9693, 12006,  9038, 10279, 36122,  9960,\n",
       "          8405, 10826, 18988, 25998,  9292,  7671,  9465,  7489,  9277, 10137,\n",
       "          9677,  9248,  9912, 12834, 11488, 13417,  7407,  8428,  8137,  9430,\n",
       "         14222, 11356, 10061,  9885, 19265,  9377, 20305,  7991,  9178,  9648,\n",
       "          9133, 10021, 10138, 30315, 21833,  9362,  9301,  9685, 11584,  9447,\n",
       "         42129, 10124,  7532, 17932, 47123, 37544,  9355, 15632,  9124, 10536,\n",
       "         13530, 12204,  9184, 36152,  9673,  9788,  9029, 11764]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1f25c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "근육이 커지기 위해서는 무엇보다 규칙적인 생활습관이 중요하다.\n",
      "특히, 아침식사는 단백질과 비타민이 풍부한 과일과 채소를 많이 섭취하는 것이 좋다.\n",
      "또한 하루 30분 이상 충분한 수면을 취하는 것도 도움이 된다.\n",
      "아침 식사를 거르지 않고 규칙적으로 운동을 하면 혈액순환에 도움을 줄 뿐만 아니라 신진대사를 촉진해 체내 노폐물을 배출하고 혈압을 낮춰준다.\n",
      "운동은 하루에 10분 정도만 하는 게 좋으며 운동 후에는 반드시 스트레칭을 통해 근육량을 늘리고 유연성을 높여야 한다.\n",
      "운동 후 바로 잠자리에 드는 것은 피해야 하며 특히 아침에 일어나면 몸이 피곤해지기 때문에 무리하게 움직이면 오히려 역효과가 날 수도 있다.\n",
      "운동을\n"
     ]
    }
   ],
   "source": [
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5b39c",
   "metadata": {},
   "source": [
    "# 공부하면 좋은 한국어 BERT 모델과 파생 모델들\n",
    "\n",
    "#### KoGPT: 한국어 문장 생성 테스크\n",
    "#### KoBART: 한국어 문서 요약 테스크 \n",
    "#### KoBERT: 한국어 표현 임베딩 얻기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5b2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2_py38",
   "language": "python",
   "name": "tensorflow2_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
